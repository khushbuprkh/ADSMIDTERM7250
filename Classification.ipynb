{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os \n",
    "import time\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileDir = os.path.dirname(os.path.realpath('__file__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khushbu\\Assignments\\Ads_MidTerm\n"
     ]
    }
   ],
   "source": [
    "print(fileDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseUrl='https://freddiemac.embs.com/FLoan/'\n",
    "postUrl='Data/download.php'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createCredentialData(user, passwd):\n",
    "    creds={'username': user,'password': passwd}\n",
    "    return creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFilesFromFreddieMac(cred,quater,year,quaterTwo,yearTwo):\n",
    "    c=cred\n",
    "    ## We are using inside WITH BLock so that session is closed ASAP with BLock is exited \n",
    "    with requests.Session() as s:\n",
    "        ## Step 1 routing to auth.php Site with the proper crentials \n",
    "        urlOne = s.post(baseUrl+\"secure/auth.php\", data=cred) \n",
    "        if \"Please log in\" in urlOne.text:\n",
    "        ## IF CREDENTIALS are not valid Throw Alert \n",
    "            print(\"Alert: Invalid Credentials, Please try again or sign up on below site \\n https://freddiemac.embs.com/FLoan/Bin/loginrequest.php\")\n",
    "        else:\n",
    "            print(\"Step1: Logged in\")\n",
    "        ## Sterp 2 Preparing the data for to Accept terms and Conditions \n",
    "            pay2={'accept': 'Yes','acceptSubmit':'Continue','action':'acceptTandC'}\n",
    "            finalUrl=s.post(baseUrl +\"Data/download.php\",pay2)\n",
    "            if \"Loan-Level Dataset\" in finalUrl.text:\n",
    "                      print(\"Step2 : Terms and Conditions Accepted\")\n",
    "                      soup = BeautifulSoup(finalUrl.content, \"html.parser\")   \n",
    "                      links_list = soup.findAll('a')\n",
    "                      print(\"Step3: Filtered the Sample Files with Condition =\" + year)\n",
    "                      print(\"Status::::::::::\")\n",
    "                      for ele in links_list:\n",
    "        ## Filtering the ZIp files = 2005 \n",
    "                         if 'historical' in ele.get_text():\n",
    "                            if(ele.get_text()[-8:-4] == year):\n",
    "                                    print(ele.get_text()[-8:-4])\n",
    "                                    if(ele.get_text()[-10:-8] == quater):\n",
    "                                        print(ele.get_text()[-10:-8])\n",
    "                                        \n",
    "                                        tempUrl = baseUrl+\"Data/\"+ele.get('href')                         \n",
    "                                        b =time.time()\n",
    "                                        downloadUrl=s.post(tempUrl) ## return type = Response\n",
    "                                        e=time.time()\n",
    "                                        print(tempUrl + \" took \"+ str(e-b)+\" sec\")\n",
    "                                        with ZipFile(BytesIO(downloadUrl.content)) as zfile:\n",
    "                                              zfile.extractall(os.path.join(fileDir, 'adsDataRepo/'+'Historical_data_'+ele.get_text()[-8:-4]+'/'))\n",
    "                                              print(\"File \"+ ele.get_text()+\" Downloaded\")\n",
    "                            \n",
    "                            if(ele.get_text()[-8:-4] == yearTwo):\n",
    "                                    print(ele.get_text()[-8:-4])\n",
    "                                    if(ele.get_text()[-10:-8] == quaterTwo):\n",
    "                                        print(ele.get_text()[-10:-8])\n",
    "                                        \n",
    "                                        tempUrl = baseUrl+\"Data/\"+ele.get('href')                         \n",
    "                                        b =time.time()\n",
    "                                        downloadUrl=s.post(tempUrl) ## return type = Response\n",
    "                                        e=time.time()\n",
    "                                        print(tempUrl + \" took \"+ str(e-b)+\" sec\")\n",
    "                                        with ZipFile(BytesIO(downloadUrl.content)) as zfile:\n",
    "                                              zfile.extractall(os.path.join(fileDir, 'adsDataRepo/'+'Historical_data_'+ele.get_text()[-8:-4]+'/'))\n",
    "                                              print(\"File \"+ ele.get_text()+\" Downloaded\")\n",
    "                                \n",
    "                                              \n",
    "    \n",
    "            else:\n",
    "                print(\"Alert: Please Check the rerouting action suffix\")\n",
    "        \n",
    "        ##To scrape the data from the Site finalUrl.       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcessData(inputQuater,inputYear,inputQuaterTwo,inputYearTwo):\n",
    "    print(\"pre-process data\")\n",
    "    if(os.path.exists(fileDir+'/adsDataRepo/')):\n",
    "        trainingDataFile = glob.glob(fileDir+'/adsDataRepo/'+'Historical_data_'+inputYear+'/historical_data1_'+inputQuater+inputYear+'.txt')\n",
    "        testingDataFile = glob.glob(fileDir+'/adsDataRepo/'+'Historical_data_'+inputYearTwo+'/historical_data1_'+inputQuaterTwo+inputYearTwo+'.txt')\n",
    "        headerNames = ['CreditScore','FirstPaymentDate','FirstTimeHomeBuyerFlag','MaturityDate','MSA','MIP','NumberOfUnits',\n",
    "                         'OccupancyStatus','OCLTV','DTI','OriginalUPB','OLTV','OriginalInterestRate','Channel','PrepaymentPenaltyFlag',\n",
    "                         'ProductType','PropertyState','PropertyType','PostalCode','LoanSequenceNumber','LoanPurpose',\n",
    "                         'OriginalLoanTerm','NumberOfBorrowers','SellerName','ServicerName','SuperConformingFlag']\n",
    "        with open(trainingDataFile[0]) as f:\n",
    "            dataf = pd.read_table(f, sep='|', low_memory=False, header=None,lineterminator='\\n', names= headerNames)\n",
    "            cleandataOne = originationDatacleaning(dataf)\n",
    "            cleandataOne.to_csv(\"Origination_Clean_\"+inputQuater+inputYear+\".csv\",index=False)\n",
    "            print(\"training data cleaned, CSV Created\")\n",
    "       \n",
    "        with open(testingDataFile[0]) as f:\n",
    "            dataf = pd.read_table(f, sep='|', low_memory=False, header=None,lineterminator='\\n', names= headerNames)\n",
    "            cleandataTwo = originationDatacleaning(dataf)\n",
    "            cleandataTwo.to_csv(\"Origination_Clean_\"+inputQuaterTwo+inputYearTwo+\".csv\",index=False)\n",
    "            print(\"testing data cleaned, CSV Created\")\n",
    "        return cleandataOne,cleandataTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def originationDatacleaning(dataf):\n",
    "    dataf['CreditScore'].replace('   ',301,inplace=True)\n",
    "    dataf['FirstTimeHomeBuyerFlag'].fillna('X',inplace=True) \n",
    "    dataf['MSA'].fillna(0, inplace=True) \n",
    "    dataf['MIP'].replace('', np.NaN).fillna(0, inplace=True)\n",
    "    dataf['NumberOfUnits'].fillna(0,inplace=True)\n",
    "    dataf['OccupancyStatus'].fillna('X',inplace=True)\n",
    "    dataf['OCLTV'].fillna(0,inplace=True)\n",
    "    dataf['DTI'].replace('   ',0,inplace=True)\n",
    "    dataf['OriginalUPB'].replace('', np.NaN).fillna(0,inplace=True)\n",
    "    dataf['OLTV'].fillna(0,inplace=True)\n",
    "    dataf['OriginalInterestRate'].fillna(0,inplace=True)\n",
    "    dataf['Channel'].fillna('X',inplace=True)\n",
    "    dataf['PrepaymentPenaltyFlag'].fillna('X',inplace=True)\n",
    "    dataf['ProductType'].fillna('XXXXX',inplace=True)\n",
    "    dataf['PropertyState'].fillna('XX',inplace=True)\n",
    "    dataf['PropertyType'].fillna('XX',inplace=True)\n",
    "    dataf['PostalCode'].replace('', np.NaN).fillna(0,inplace=True)\n",
    "    dataf['LoanSequenceNumber'].replace('', np.NaN).fillna(0,inplace=True)\n",
    "    dataf['LoanPurpose'].fillna('X',inplace=True)\n",
    "    dataf['OriginalLoanTerm'].replace('', np.NaN).fillna(0,inplace=True)\n",
    "    dataf['NumberOfBorrowers'].fillna('01',inplace=True)\n",
    "    dataf['SellerName'].fillna('X',inplace=True)\n",
    "    dataf['ServicerName'].fillna('X',inplace=True)\n",
    "    dataf['SuperConformingFlag'].fillna('X',inplace=True)\n",
    "    \n",
    "    #assingning data \n",
    "    \n",
    "    dataf[['FirstTimeHomeBuyerFlag','OccupancyStatus','Channel','PrepaymentPenaltyFlag','ProductType','PropertyState','PropertyType','LoanSequenceNumber','LoanPurpose',\n",
    "           'SellerName','ServicerName','SuperConformingFlag']]=dataf[['FirstTimeHomeBuyerFlag','OccupancyStatus','Channel','PrepaymentPenaltyFlag','ProductType','PropertyState','PropertyType','LoanSequenceNumber','LoanPurpose',\n",
    "           'SellerName','ServicerName','SuperConformingFlag']].astype('str')\n",
    "    dataf[['OriginalInterestRate']]=dataf[['OriginalInterestRate']].astype('float64')\n",
    "    dataf[['OriginalUPB']]= dataf[['OriginalUPB']].astype('int64')\n",
    "    \n",
    "    #missinganalysis(dataf)\n",
    "    \n",
    "    #\n",
    "    return dataf\n",
    "    '''As we can see we have the below Null Values presnt in the Data for all the Years (Only varying the Counts )\n",
    "                       MSA           \n",
    "    FirstTimeHomeBuyerFlag           \n",
    "     PrepaymentPenaltyFlag          \n",
    "         NumberOfBorrowers \n",
    "    We can ignore''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter QuaterQ1\n",
      "Enter year2007\n",
      "1\n",
      "2\n",
      "pre-process data\n",
      "training data cleaned, CSV Created\n",
      "testing data cleaned, CSV Created\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    creds=createCredentialData(\"maiti.t@husky.neu.edu\",\"qRX7JXN4\")\n",
    "    inputQuater= raw_input('Enter Quater')\n",
    "    inputYear= raw_input('Enter year')\n",
    "    print(inputQuater[1:2])\n",
    "    #getFilesFromFreddieMac(creds,inputQuater,inputYear)\n",
    "    if(int(inputQuater[1:2])<4):\n",
    "        temp = int(inputQuater[1:2])\n",
    "        temp += 1\n",
    "        print(temp)\n",
    "        t=str(temp)\n",
    "        newQuater=\"Q\"+t\n",
    "        inputQuaterTwo=newQuater\n",
    "        #getFilesFromFreddieMac(creds,inputQuater,inputYear,inputQuaterTwo,inputYear)\n",
    "        preProcessData(inputQuater,inputYear,inputQuaterTwo,inputYear)\n",
    "    else:\n",
    "        year = int(inputYear)+1\n",
    "        inputYearTwo=str(year)\n",
    "        inputQuaterTwo=\"Q1\"\n",
    "        #getFilesFromFreddieMac(creds,inputQuater,inputYear,inputQuaterTwo,inputYearTwo)\n",
    "        preProcessData(inputQuater,inputYear,inputQuaterTwo,inputYearTwo)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
